{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AAfLrhOhsaHz",
        "eBTTuH9QtLce",
        "HV6oiPlWFpKP",
        "d9G51waBSu4i",
        "U3D1HjBCIO37",
        "GkJcbvvjS_eD",
        "6caUJi3NVgJK",
        "G3cS1H6mVijG",
        "j8vLjLvnaebf"
      ],
      "authorship_tag": "ABX9TyN9RXUrviKsmeTezVRucV4s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TayJen/hackathon_algu2022/blob/master/H_ALGU_2022_Best_Old_Advance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFVPXkf-r0R-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь необходимо разместить путь, по которому будут расположены данные"
      ],
      "metadata": {
        "id": "qPA4jx5fPZAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/Shareddrives/data_drive/H_Vladivostok2022\n",
        "!pwd"
      ],
      "metadata": {
        "id": "Ajt0xnRYr_aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек"
      ],
      "metadata": {
        "id": "AAfLrhOhsaHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Для работы с данными\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Для визуализации\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Для работы с текстом\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import wordnet, stopwords\n",
        "from pymystem3 import Mystem\n",
        "\n",
        "# Для моделей\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Метрика\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "%matplotlib inline\n",
        "mpl.rcParams['figure.facecolor'] = 'white'\n",
        "np.random.seed(59)\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "H7rpBM58r_cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Работа с данными"
      ],
      "metadata": {
        "id": "eBTTuH9QtLce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Основные данные"
      ],
      "metadata": {
        "id": "3mCmx1dbFl84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем данные"
      ],
      "metadata": {
        "id": "KlN-dv7tu7hI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./data/train/train_issues.csv\")"
      ],
      "metadata": {
        "id": "P4sCxLgxu8-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Работа со временем"
      ],
      "metadata": {
        "id": "TgBRw49zt6ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['created_time'] = pd.to_datetime(df['created'], format='%Y-%m-%d %H:%M:%S')\n",
        "df['month'] = df['created_time'].dt.month\n",
        "df['day'] = df['created_time'].dt.day\n",
        "df['hour'] = df['created_time'].dt.hour\n",
        "df['minute'] = df['created_time'].dt.minute\n",
        "\n",
        "df.drop(['created', 'created_time'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "vbcT8f2Hr_en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Работа с ключем задачи"
      ],
      "metadata": {
        "id": "kpxIpPyDt8Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['key_name'] = df['key'].apply(lambda x: x.split('-')[0])\n",
        "df['key_num'] = df['key'].apply(lambda x: x.split('-')[1]).astype('int64')\n",
        "\n",
        "df.drop(['key'], axis=1, inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QdO-WxwWr_go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Работа с описанием задачи"
      ],
      "metadata": {
        "id": "E21LgklOt9v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = Mystem()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "w_tokenizer = WhitespaceTokenizer()"
      ],
      "metadata": {
        "id": "IijOGXhuuMNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для того чтобы лемматизация работала, необходимо раскомментировать первые две строки при первом запуске"
      ],
      "metadata": {
        "id": "c8an7QotuRJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
        "# !tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!cp mystem /root/.local/bin/mystem"
      ],
      "metadata": {
        "id": "qx5o7-dMuNG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_text(text):\n",
        "    t = re.sub(r'[^a-zA-Zа-яА-ЯёЁ\\' ]', ' ', text)\n",
        "    t = ' '.join(t.split())\n",
        "    return t\n",
        "\n",
        "def lemmatize_text_rus(text):\n",
        "    tokens = m.lemmatize(text.lower())\n",
        "    tokens = [token for token in tokens if token != '\\n']\n",
        "    text = \" \".join(tokens)\n",
        "    \n",
        "    return text\n",
        "\n",
        "def pos_tagger(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:         \n",
        "        return None\n",
        "\n",
        "def lemmatize_with_pos_eng(text):\n",
        "    pos_tagged = nltk.pos_tag(w_tokenizer.tokenize(text))\n",
        "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
        "    lemmatized_sentence = []\n",
        "    for word, tag in wordnet_tagged:\n",
        "        if tag is None:\n",
        "            lemmatized_sentence.append(word)\n",
        "        else:       \n",
        "            lemmatized_sentence.append(lemmatizer.lemmatize(word, pos=tag))\n",
        "    lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
        "    return lemmatized_sentence\n",
        "\n",
        "\n",
        "df['clear_summary'] = df['summary'].apply(clear_text)\n",
        "df['clear_summary'] = df['clear_summary'].str.lower()\n",
        "df['lemm_summary'] = df['clear_summary'].apply(lemmatize_text_rus)\n",
        "df['lemm_summary'] = df['lemm_summary'].apply(lemmatize_with_pos_eng)\n",
        "\n",
        "df.drop(['summary', 'clear_summary'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Y7OEgskar_ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эти стоп-слова пригодятся нам в дальнейшем при использовании tf-idf"
      ],
      "metadata": {
        "id": "kvmDILbfE-Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_rus = stopwords.words(\"russian\")\n",
        "stopwords_eng = stopwords.words('english')\n",
        "stopwords_all = stopwords_rus + stopwords_eng\n",
        "\n",
        "count_tf_idf = TfidfVectorizer(stop_words=stopwords_all)"
      ],
      "metadata": {
        "id": "jGNtHADhE9d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем таргет, чтобы исключить выбросы и минимизировать разброс"
      ],
      "metadata": {
        "id": "XEaCl0e2vQpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['log_target'] = np.log(df['overall_worklogs'])\n",
        "df.drop(['overall_worklogs'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "lsZqkcbCr_kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Присоединяем дополнительные данные"
      ],
      "metadata": {
        "id": "X_QcTLIbFbGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Информация о работниках"
      ],
      "metadata": {
        "id": "HV6oiPlWFpKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем данные"
      ],
      "metadata": {
        "id": "jR2LswhjFh3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_emp = pd.read_csv(\"./data/employees.csv\")"
      ],
      "metadata": {
        "id": "Ga2DYeBvr_m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сразу отбросим бесполезное"
      ],
      "metadata": {
        "id": "uuW-ZP79Fy5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_emp.drop(['english_level', 'salary_calculation_type', 'full_name'],\n",
        "            axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "uIDlv_26r_qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_emp['payment_type'].fillna('unknown', inplace=True)\n",
        "df_emp['hiring_type'].fillna('unknown', inplace=True)"
      ],
      "metadata": {
        "id": "LmJk7nyNr_r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def position_cleaning(x):\n",
        "    if x is np.NaN:\n",
        "        return x\n",
        "    \n",
        "    x = x.lower().strip().replace('-', ' ')\n",
        "\n",
        "    key_positions = ['web', 'директор', 'руководитель',\n",
        "                     'devops', 'рекрутер', 'бухгалтер',\n",
        "                     'hr', 'тестировщик']\n",
        "\n",
        "    for key_pos in key_positions:\n",
        "        if key_pos in x:\n",
        "            x = key_pos\n",
        "            break\n",
        "    \n",
        "    if x == 'рекрутер' or x == 'специалист отдела по управлению персоналом' or x == 'сорсер':\n",
        "        return 'hr'\n",
        "    elif x == 'графический дизайнер':\n",
        "        return 'web'\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "df_emp['position'] = df_emp['position'].apply(position_cleaning)\n",
        "pos_pop = df_emp['position'].value_counts()"
      ],
      "metadata": {
        "id": "RT97zoe4GsRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remark_pos(x):\n",
        "    if x is np.NaN or pos_pop[x] < 3:\n",
        "        return 'other'\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "df_emp['position'] = df_emp['position'].apply(remark_pos)\n",
        "df_emp.head()"
      ],
      "metadata": {
        "id": "75bzMCpyHWs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Присоединяем информацию о работниках"
      ],
      "metadata": {
        "id": "eTk_9XGYGHSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(df, df_emp, left_on=\"assignee_id\", right_on=\"id\",\n",
        "              how='left', suffixes=('', '_y'))\n",
        "\n",
        "df.drop(['id_y'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "hWpusyvcr_vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "RJlQMXytr_x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Информация о комментариях"
      ],
      "metadata": {
        "id": "d9G51waBSu4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_coms = pd.read_csv(\"./data/train/train_comments.csv\")"
      ],
      "metadata": {
        "id": "mIwX9CpWSx2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_coms_counts = df_coms.groupby('issue_id').agg({'comment_id': 'count',\n",
        "                                                  'author_id': 'nunique'})\n",
        "df_coms_counts.reset_index(inplace=True)\n",
        "df_coms_counts.rename(columns={\"comment_id\":\"comments_cnt\",\n",
        "                               \"author_id\":\"authors_cnt\"},\n",
        "                      inplace=True)\n",
        "df_coms_counts.head()"
      ],
      "metadata": {
        "id": "8vK5MfNnSx4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(df, df_coms_counts, left_on=\"id\", right_on=\"issue_id\", how='left')\n",
        "df.drop(['id', 'issue_id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "PvsQqUfISx6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['comments_cnt'] = df['comments_cnt'].fillna(0).astype('int32')\n",
        "df['authors_cnt'] = df['authors_cnt'].fillna(0).astype('int32')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qR80ew0qSx8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Разделение данных"
      ],
      "metadata": {
        "id": "U3D1HjBCIO37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['log_target'], axis=1)\n",
        "y = df[['log_target']]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=59)\n",
        "X_train.reset_index(inplace=True, drop=True)\n",
        "X_val.reset_index(inplace=True, drop=True)\n",
        "y_train = y_train.values\n",
        "y_val = y_val.values\n",
        "X_train.shape, X_val.shape"
      ],
      "metadata": {
        "id": "4RQHUI1or_zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "n1e-GQpWRoWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Применяем tf-idf"
      ],
      "metadata": {
        "id": "ezAr-6XmKex6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_new = count_tf_idf.fit_transform(X_train['lemm_summary'])\n",
        "feature_names_tf = list(map(lambda x: x + '_tf', count_tf_idf.get_feature_names_out()))\n",
        "\n",
        "X_train_new_df = pd.DataFrame(X_train_new.toarray(), columns=feature_names_tf)\n",
        "X_train.drop('lemm_summary', axis=1, inplace=True)\n",
        "X_train = pd.concat([X_train, X_train_new_df], axis=1)\n",
        "\n",
        "X_val_new = count_tf_idf.transform(X_val['lemm_summary'])\n",
        "X_val_new_df = pd.DataFrame(X_val_new.toarray(), columns=feature_names_tf)\n",
        "X_val.drop('lemm_summary', axis=1, inplace=True)\n",
        "X_val = pd.concat([X_val, X_val_new_df], axis=1)\n",
        "\n",
        "X_train.shape, X_val.shape"
      ],
      "metadata": {
        "id": "LTSkiwZhKd_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "FDAhxUZIN7vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Применяем Label Encoding (так как ключевыми моделями будут деревья и их производные, то выбор справедлив)"
      ],
      "metadata": {
        "id": "DiGvfpQDLDfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = ['key_name', 'position',\n",
        "                'hiring_type', 'payment_type']\n",
        "\n",
        "ord_encoder = OrdinalEncoder(handle_unknown='use_encoded_value',\n",
        "                                unknown_value=-1)\n",
        "X_train[cat_features] = ord_encoder.fit_transform(X_train[cat_features])\n",
        "X_val[cat_features] = ord_encoder.transform(X_val[cat_features])"
      ],
      "metadata": {
        "id": "mAiYoF57IK-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "H5MPcvgjREOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Работа с моделью"
      ],
      "metadata": {
        "id": "GkJcbvvjS_eD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBRegressor(max_depth=21, random_state=59)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "7M2FNnIbILE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_val)\n",
        "score = r2_score(y_val, pred)\n",
        "score"
      ],
      "metadata": {
        "id": "QWG8T3emILGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Анализ модели"
      ],
      "metadata": {
        "id": "lkE4b3KpOgYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = model.get_booster().get_score(importance_type='weight')\n",
        "keys = list(feature_importance.keys())\n",
        "values = list(feature_importance.values())\n",
        "\n",
        "data = pd.DataFrame(data=values, index=keys,\n",
        "                    columns=[\"score\"]).sort_values(by=\"score\", ascending=False)\n",
        "data.nlargest(40, columns=\"score\").plot(kind='barh', figsize=(20, 10)) ## plot top 40 features"
      ],
      "metadata": {
        "id": "LDIvB0h7Oirk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "-TLQo5-tOrUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Сабмит на сайт"
      ],
      "metadata": {
        "id": "6caUJi3NVgJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обработка тестовых данных"
      ],
      "metadata": {
        "id": "G3cS1H6mVijG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем данные"
      ],
      "metadata": {
        "id": "WCmIgHdwVnOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"./data/test/test_issues.csv\")"
      ],
      "metadata": {
        "id": "KQ6qE0t5TkN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['created_time'] = pd.to_datetime(df_test['created'], format='%Y-%m-%d %H:%M:%S')\n",
        "df_test['month'] = df_test['created_time'].dt.month\n",
        "df_test['day'] = df_test['created_time'].dt.day\n",
        "df_test['hour'] = df_test['created_time'].dt.hour\n",
        "df_test['minute'] = df_test['created_time'].dt.minute\n",
        "\n",
        "df_test['key_name'] = df_test['key'].apply(lambda x: x.split('-')[0])\n",
        "df_test['key_num'] = df_test['key'].apply(lambda x: x.split('-')[1]).astype('int64')\n",
        "\n",
        "df_test['clear_summary'] = df_test['summary'].apply(clear_text)\n",
        "df_test['clear_summary'] = df_test['clear_summary'].str.lower()\n",
        "df_test['lemm_summary'] = df_test['clear_summary'].apply(lemmatize_text_rus)\n",
        "df_test['lemm_summary'] = df_test['lemm_summary'].apply(lemmatize_with_pos_eng)\n",
        "\n",
        "df_test = pd.merge(df_test, df_emp, left_on=\"assignee_id\", right_on=\"id\",\n",
        "                   how='left', suffixes=('', '_y'))\n",
        "\n",
        "df_test.drop(['created', 'created_time'], axis=1, inplace=True)\n",
        "df_test.drop(['key'], axis=1, inplace=True)\n",
        "df_test.drop(['summary', 'clear_summary'], axis=1, inplace=True)\n",
        "df_test.drop(['id_y'], axis=1, inplace=True)\n",
        "\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "zKQZKJ5kTkQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_coms_test = pd.read_csv('./data/test/test_comments.csv')\n",
        "df_coms_counts_test = df_coms_test.groupby('issue_id').agg({'comment_id': 'count',\n",
        "                                                            'author_id': 'nunique'})\n",
        "df_coms_counts_test.reset_index(inplace=True)\n",
        "df_coms_counts_test.rename(columns={\"comment_id\":\"comments_cnt\",\n",
        "                                    \"author_id\":\"authors_cnt\"},\n",
        "                           inplace=True)\n",
        "df_coms_counts_test.head()"
      ],
      "metadata": {
        "id": "k7ynZBGVVG8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.merge(df_test, df_coms_counts_test,\n",
        "                   left_on=\"id\", right_on=\"issue_id\", how='left')\n",
        "df_test.drop(['id', 'issue_id'], axis=1, inplace=True)\n",
        "df_test['comments_cnt'] = df_test['comments_cnt'].fillna(0).astype('int32')\n",
        "df_test['authors_cnt'] = df_test['authors_cnt'].fillna(0).astype('int32')\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "YX_Fdp5NVqN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_new = count_tf_idf.transform(df_test['lemm_summary'])\n",
        "X_test_new_df = pd.DataFrame(X_test_new.toarray(), columns=feature_names_tf)\n",
        "df_test.drop('lemm_summary', axis=1, inplace=True)\n",
        "X_test = pd.concat([df_test, X_test_new_df], axis=1)\n",
        "X_test[cat_features] = ord_encoder.transform(X_test[cat_features])\n",
        "X_test.shape"
      ],
      "metadata": {
        "id": "QNlTYZ_CVqDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = np.rint(np.exp(model.predict(X_test))).astype('int64')\n",
        "pred_test"
      ],
      "metadata": {
        "id": "a7CjxE1OVqFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создаем датафрейм с предсказанием"
      ],
      "metadata": {
        "id": "HdGu9SYnXpKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample = pd.read_csv('./data/sample_solution.csv')\n",
        "len(pred_test), len(df_sample)"
      ],
      "metadata": {
        "id": "j3NGLwQBVqHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample.overall_worklogs = pred_test\n",
        "df_sample.to_csv('./solutions/xgb_tfidf_d21.csv', index=False)"
      ],
      "metadata": {
        "id": "XfLbmdalTkSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Проверяем предсказание"
      ],
      "metadata": {
        "id": "F83R9x24X6Ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_solution = pd.read_csv('./solutions/xgb_tfidf_d21.csv')\n",
        "df_solution.head()"
      ],
      "metadata": {
        "id": "En-ToqqoTkUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_solution.describe()"
      ],
      "metadata": {
        "id": "m6YA7rYdeqjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_solution.info()"
      ],
      "metadata": {
        "id": "ajIenid8e_7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Преобразование среднего"
      ],
      "metadata": {
        "id": "j8vLjLvnaebf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем к тренировочному распределению"
      ],
      "metadata": {
        "id": "tpArPYIK3HUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./data/train/train_issues.csv\")\n",
        "\n",
        "orig_mean = int(df.overall_worklogs.mean())\n",
        "sol_mean = int(df_solution.overall_worklogs.mean())\n",
        "orig_mean, sol_mean"
      ],
      "metadata": {
        "id": "Y9eH_bbvr_1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_dist(x):\n",
        "    x = x + orig_mean - sol_mean\n",
        "    return x"
      ],
      "metadata": {
        "id": "XsSh54yu7OWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_solution['overall_worklogs'] = df_solution['overall_worklogs'].apply(transform_dist)\n",
        "df_solution.head()"
      ],
      "metadata": {
        "id": "1aYg8RXeau4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_solution.describe()"
      ],
      "metadata": {
        "id": "NPLXOODdewY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_solution.info()"
      ],
      "metadata": {
        "id": "-EuirNMwfGm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_solution.to_csv('./solutions/d21_only_mean_trans.csv', index=False)"
      ],
      "metadata": {
        "id": "ClOSclobbI5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверка предсказания"
      ],
      "metadata": {
        "id": "OwjrtvUbgxVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_solution = pd.read_csv('./solutions/d21_only_mean_trans.csv')\n",
        "df_solution.head()"
      ],
      "metadata": {
        "id": "inM04MKnbb2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qesoFDAAYOBz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}